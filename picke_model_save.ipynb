{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://85c0014d-3467-4f00-ab96-b2dc980f3fd9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://85c0014d-3467-4f00-ab96-b2dc980f3fd9/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://be61c957-2ef8-4055-8f07-44413608c81b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://be61c957-2ef8-4055-8f07-44413608c81b/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c9b3267b-3ad2-4c79-af2e-93e2ad064508/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c9b3267b-3ad2-4c79-af2e-93e2ad064508/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/0912.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "\n",
    "name1 = 'model/0329'\n",
    "name2 = 'model/0629'\n",
    "name3 = 'model/0912'\n",
    "\n",
    "\n",
    "model1 = load_model(name1 + '.h5')\n",
    "joblib.dump(model1, name1 + '.pkl')\n",
    "\n",
    "model2 = load_model(name2 + '.h5')\n",
    "joblib.dump(model2, name2 + '.pkl')\n",
    "\n",
    "model3 = load_model(name3 + '.h5')\n",
    "joblib.dump(model3, name3 + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "score=[[0.91093916]] : matched\n",
      "WorkingTime: 0.25304388999938965sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-17 13:44:06.978784: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# new user fingerprint input\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#best_model = load_model(model_name)\n",
    "best_model = joblib.load('model/test_model_joblib.pkl')\n",
    "\n",
    "img1_name = 'test_data/mj2.png'\n",
    "img2_name = 'test_data/mj3.png'\n",
    "\n",
    "input_img1 = cv2.imread(img1_name ,cv2.IMREAD_GRAYSCALE)\n",
    "input_img2 = cv2.imread(img2_name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "input_img11 = cv2.resize(input_img1, (90, 90)).reshape((1, 90, 90, 1)).astype(np.float32) /255\n",
    "input_img22 = cv2.resize(input_img2, (90, 90)).reshape((1, 90, 90, 1)).astype(np.float32) / 255.\n",
    "\n",
    "input_data = []\n",
    "input_data.append(input_img11)\n",
    "input_data.append(input_img22)\n",
    "input_data = np.array(input_data)\n",
    "\n",
    "pred_rx = best_model.predict((input_data[0], input_data[1]))\n",
    "\n",
    "if pred_rx > 0.5:\n",
    "    print('score={} : matched'.format(pred_rx))\n",
    "    print('WorkingTime: {}sec'.format(time.time()-start_time))\n",
    "\n",
    "else:\n",
    "    print('score={} : unmatched'.format(pred_rx))\n",
    "    print('WorkingTime: {}sec'.format(time.time()-start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9597c5a3b4c72d1d3d7aaf583ba91ab324472e797de20f453cdf5baf4283e79b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
